<h2>3.8 Performance Monitoring and Evaluation</h2>

<p>
  Generative AI tools are constantly learning and changing. Once a tool is
  implemented, the IPT must closely monitor how it is used and the outputs.
  Consider provisions in contracts requiring vendors to submit deliverables that
  help monitor and control for risks in using the tools.
</p>

<h3>3.8.1 Maintaining the IPT</h3>
<p>
  Continuing the Generative AI IPT for the full lifecycle of using the tool
  brings multiple benefits.
</p>

<h4>Training</h4>
<p>
  The IPT can develop or collect and make available appropriate training
  materials and deliver them to the end users. Part of this training should
  identify the changing nature of generative AI tools to help identify if the
  product is not functioning correctly.
</p>

<h4>Incident Detection and Response</h4>
<p>
  Build in reporting and redress procedures for when something goes wrong
  working in collaboration with your agency’s teams that address IT risks. This
  is particularly important when Generative AI tools and their outputs may be
  used in a manner impacting benefits, rights or norms. Robust bias detection
  and mitigation strategies help to stay ahead of problems. Audit and oversight
  mechanisms can flag when incidents occur and when model performance is
  degrading. All of these will help identify when models may need to be
  refreshed, modified, or taken out of production.
</p>

<h4>Strategic Objectives</h4>
<p>
  Regularly reviewing and adjusting Generative AI strategies helps ensure they
  remain effective and aligned with your agency’s goals.
</p>

<h3>3.8.2 Engage regularly with vendors</h3>
<p>
  The inputs and outputs of Generative AI tools may change the functionality and
  performance of the product. Successfully managing a Generative AI acquisition
  requires frequent communication with vendors.
</p>

<h4>Meeting Performance and Ethical Standards</h4>
<p>
  Before contract award (even at the solicitation stage and/or built into
  evaluation criteria), meeting with vendors can offer the chance to clearly
  define how they will meet performance and ethical standards and mitigate risks
  associated with the tool. Clarify the roles and responsibilities of vendors,
  particularly if a use case has an impact on citizen rights, entitlements or
  other benefit programs.
</p>

<h4>Resolving Disputes</h4>
<p>
  Agree on areas of uncertainty that exist with the generative AI tool and how
  to navigate issues or disputes between the government and the vendor providing
  the model. Document these agreements and identify a cadence to review and
  update them ensuring your legal support is included in the process.
</p>

<h4>Updating Products</h4>
<p>
  Identify procedures to measure and support trust and assurance for products.
  This should include testing and system update cycles and identifying new
  capabilities incorporated into the products. Also regularly review any changes
  in commercial terms and conditions around data and data usage. Consider doing
  this through a Service Level Agreement (SLA) or other mechanism which the IPT
  can use to monitor vendor performance.
</p>

<h4>Protecting Legal Rights</h4>
<p>
  Where systems may support decisions on rights-impacting programs make sure the
  models can be contested in accordance with the laws, statutes and regulations
  governing the program.
</p>

<h4>Controlling Expenses and Costs</h4>
<p>
  Monitor costs against the cost estimates you created during the acquisition.
  Make sure invoices contain sufficient detail to monitor and control
  expenditures, particularly usage or consumption costs. Regularly communicate
  with end users and the technical team, and review invoices to make sure they
  are in alignment with how the Generative AI tools are being used.
</p>

<div class="tab-divide-line w-100"></div>
