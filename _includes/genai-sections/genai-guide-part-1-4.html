<h2 class="ext-top itvmo-article-sub-2">
  1.4. Potential Risks of Generative AI
</h2>
<p>
  Generative AI poses a range of potential risks including the ones below. This
  is not an exhaustive list. New risks are being discovered continually.
</p>
<div class="indent-article-section-1">
  <h3 class="itvmo-article-sub-3-blue">Misinformation and Disinformation</h3>
  <p>
    Generative AI can create highly realistic but false content, such as
    “deepfakes” – images, audio, video or text which make it look like someone
    said or did something they didn’t. This can be used to spread falsehoods
    that polarize people, destabilize communities, and even incite crimes.
  </p>

  <h3 class="itvmo-article-sub-3-blue">Errors and Inaccuracies</h3>
  <p>
    Generative AI models can produce incorrect or nonsensical outputs, often
    because of limitations in their training data or algorithms. These errors
    can lead to misinformation, incorrect decisions, and misinterpretations,
    which can lead to flawed policy decisions or misinformed public statements.
  </p>

  <h3 class="itvmo-article-sub-3-blue">Bias and Discrimination</h3>
  <p>
    AI systems, if they have been trained on discriminatory or one-sided data,
    can lead to unfair or discriminatory outcomes in public services.
  </p>

  <h3 class="itvmo-article-sub-3-blue">Prompt Manipulation</h3>
  <p>
    There is a risk of Generative AI systems providing biased or misleading
    outputs, especially when users deliberately input incorrect or slanted
    information. Malicious actors could exploit this to generate harmful
    content, spread disinformation, or extract sensitive data.
  </p>

  <h3 class="itvmo-article-sub-3-blue">Misalignment with Laws and Policies</h3>
  <p>
    The use of Generative AI must be carefully evaluated to ensure compliance
    with applicable laws, policies and procedures around transparency,
    accountability, and other aspects of ethical use.
  </p>

  <h3 class="itvmo-article-sub-3-blue">Security and Cybersecurity Threats</h3>
  <p>
    Generative AI can be exploited for cyber-attacks, including sophisticated
    phishing and malware that evades detection, and is vulnerable to adversarial
    attacks aimed at manipulating outputs. Insecure AI systems risk data theft
    and sabotage, undermining public trust and national security.
  </p>

  <h3 class="itvmo-article-sub-3-blue">Privacy Risks</h3>
  <p>
    The volume and type of data involved in the use of Generative AI raises
    concerns about privacy and the use and protection of personal information
    when training these technologies, inputting data and outputting content.
  </p>

  <h3 class="itvmo-article-sub-3-blue">Intellectual Property and Plagiarism</h3>
  <p>
    Generative AI raises complex issues regarding copyright infringement and
    originality. This poses significant challenges for determining the ownership
    and originality of AI-generated works.
  </p>
  <h3 class="itvmo-article-sub-3-blue">Environmental Impact</h3>
  <p>
    Similar to cloud computing, training and operating large AI models requires
    substantial computational resources, leading to significant electricity
    usage. Additionally, the production and disposal of the specialized
    computing hardware (like GPUs and CPUs) necessary for AI development involve
    resource-intensive processes and contribute to electronic waste. This
    environmental impact is compounded by the infrastructure needs of data
    centers, including land usage and cooling systems.
  </p>

  <h3 class="itvmo-article-sub-3-blue">Model Training Delay</h3>
  <p>
    Since there is a time lag between when the model is trained and when the
    model is used there is a risk that the model doesn't reflect current norms,
    regulations, or realities, which could cause the AI tool to generate
    irrelevant or inappropriate outputs.
  </p>

  <h3 class="itvmo-article-sub-3-blue">Ownership</h3>
  <p>
    Generative AI tools create data based on the inputs that it has been trained
    on and new data inputted by users. Aside from the intellectual property
    issues mentioned above, there are significant concerns over who owns the
    inputted and outputted data. If a user inputs documents for the Generative
    AI tool to use, is that data now owned by the company who owns the
    Generative AI tool or does the user still own it? If the Generative AI
    created lines of computer code, is that code now owned by the user or the
    company who owns the Generative AI tool? Is the Generative AI tool allowed
    to “learn” from the data it created and use it to create code for some other
    user?
  </p>
</div>
