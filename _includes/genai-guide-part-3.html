<div class="contents padding-bottom-5">
  <div id="guide-chapter-3">
    <h2>3. Generative AI Procurement</h2>

    <h2>Select Components of a Generative AI Acquisition</h2>
    <p>
      Acquiring Generative AI solutions can look very similar to other
      software acquisitions plus a few specific considerations.
    </p>

    <p>
      If you are not familiar with purchasing software or have not conducted
      a software acquisition recently, consider reviewing the information at
      the
      <a
        class="external_link"
        href="https://techfarhub.usds.gov/get-started/"
        >TechFAR Hub</a
      >
      or seeking out some additional training from the providers listed on
      the site or your agency.
    </p>

    <p>
      Here are select components of a Generative AI acquisition. These are
      starting points and don’t represent the only practices or approaches
      for acquiring Generative AI. This also is not a strict sequence as
      much as it is a collection of focus areas that should be considered as
      part of any Generative AI acquisition.
    </p>

    <p>
      Additionally, your agency may have specific requirements, policies and
      guidelines that you must follow as part of any Generative AI
      acquisition.
    </p>

    <p>3.1 Integrated Product Team</p>
    <p>3.2 Agency Goals and Needs</p>
    <p>3.3 Solutions Scoping and Testing</p>
    <p>3.4 Data Management and Protection</p>
    <p>3.5 Acquisition Strategy</p>
    <p>3.6 Market Assessment</p>
    <p>3.7 Cost Estimation</p>
    <p>3.8 Performance Monitoring and Evaluation</p>

    <h2>3.1. Integrated Product Team</h2>

    <p>
      Generative AI procurement is not just a procurement or IT department
      task. Many agencies have consolidated their AI decision making under a
      Chief Artificial Intelligence Officer (CAIO). Some agencies,
      commissions and departmental components may assign this responsibility
      under their CIO or IT support organization.
    </p>

    <p>
      The CAIO plays a vital role in any Generative AI project. They are
      often the responsible official ensuring that the right policies and
      protections are in place for any AI project in their agency. They can
      be the project sponsor who is trying to get specific Generative AI
      pilots and experiments underway. They are also subject matter experts
      who can provide guidance on which are the right solutions to consider
      and how to best implement Generative AI products in the agency’s
      current technology environments. CAIOs can be strong partners for
      acquisition teams looking to help program staff get a Generative AI
      project off the ground and running smoothly.
    </p>

    <p>
      As a start, your agency’s CAIO and program officials can provide
      insight into the maturity of the agency’s IT and AI capabilities,
      policies, and skills. Your agency may already be using Generative AI
      tools and may be familiar with how to best work with them.
    </p>

    <p>
      Consider creating an Integrated Product Team (IPT) drawing from across
      the agency or sub-agency. Integrated Product Teams are successful
      because each role brings different perspectives and knowledge. Given
      the complex and cross-cutting nature of many Generative AI decisions a
      cross-agency IPT involving agency officials with expertise in the
      specific program, technology, data, and other relevant domains (e.g.,
      security, privacy, legal, finance, acquisition, etc.) can help work
      through challenges and identify opportunities. Having multiple voices
      and ideas can make working through thorny challenges more effective.
    </p>

    <p>
      Led by a technical program manager, the IPT consists of program staff
      who can voice needs and advocate for the agency’s mission, AI
      practitioners, software engineers, data engineers, security experts,
      privacy officials and acquisition professionals. Finance, legal,
      accessibility and other representatives can be brought in along the
      way.
    </p>

    <p>
      An IPT can set the project objectives and constraints, research and
      vet solutions, and identify potential risks and consequences. The team
      can identify and review agency related AI policies and guidance. In
      the case of Generative AI, the IPT can also serve as the means for
      continued monitoring and evaluation of the capability as described in
      section 3.8.
    </p>

    <p>The IPT can address these types of issues:</p>
    <ul>
      <li>
        Integration and interoperability of solutions with existing systems
        and data
      </li>
      <li>Data rights and ownership</li>
      <li>Data protections</li>
      <li>Responsible use of data and tools</li>
      <li>Intellectual property provisions</li>
      <li>End-user licensing agreements</li>
      <li>Appropriations implications for different types of pricing</li>
      <li>
        Security measures and privacy implications to start a pilot or scale
        a solution
      </li>
      <li>Performance testing, monitoring and control</li>
      <li>Accessibility considerations</li>
    </ul>

    <p>
      Refer to
      <a
        class="external_link"
        href="https://www.whitehouse.gov/wp-content/uploads/2024/03/M-24-10-Advancing-Governance-Innovation-and-Risk-Management-for-Agency-Use-of-Artificial-Intelligence.pdf"
        >OMB Management Memo M-24-10 Advancing Governance, Innovation, and
        Risk Management for Agency Use of Artificial Intelligence</a
      >
      for more details about issues an IPT can consider.
    </p>

    <p>
      Many governmentwide communities can help you charter an IPT. The
      <a
        class="external_link"
        href="https://itvmo.gsa.gov/services/it-buyers-training-and-support/?tabName=it-buyers-cop-header"
        >IT Buyers Community of Practice</a
      >
      unifies agency contracting officers, program managers, software asset
      managers, information security officers as well as industry partners
      and many other active stakeholders in the Federal IT Marketplace to
      increase access to data, tools, and information.
    </p>

    <h2>3.2 Agency Goals and Needs.</h2>

    <p>
      There are many different types of Generative AI products and services,
      each with their own strengths. Don’t jump to a particular solution
      first. Instead, begin by understanding what program staff want to do
      and achieve, then find the right solutions and suppliers that will
      best help them.
    </p>

    <p>
      Program staff and leaders can be a great source for identifying and
      refining problem statements and how they link back to the agency’s
      mission. Technical leaders including the agency Chief Information
      Officer (CIO), Chief Information Security Officer (CISO) and Chief
      Privacy Officer (CPO) offer important perspectives about what current
      systems and tools can do and how they can be used. Many agencies have
      also selected a Chief Artificial Intelligence Officer (CAIO) to
      oversee AI efforts including Generative AI work. CAIOs are a vital
      voice to have at the table when scoping agency goals and needs.
    </p>

    <p>Some potential questions to ask include:</p>
    <ul>
      <li>What specific problems does the agency want to solve?</li>
      <li>
        What opportunities does Generative AI present that the agency wants
        to pursue?
      </li>
      <li>
        Are other agencies seeking to solve similar problems or use
        Generative AI for similar purposes that you can learn from?
      </li>
      <li>
        What are gaps in current technology tools that Generative AI could
        fill?
      </li>
      <li>What are the desired outcomes of using Generative AI tools?</li>
    </ul>

    <p>
      Sometimes just by posing these questions an agency can determine that
      it already has non-Generative AI tools (and even non-AI tools) that
      can be deployed quickly or that the problems themselves aren’t worth
      the investment to solve.
    </p>

    <p>
      Many agencies are in a space of needing or wanting to experiment or
      “do something” with Generative AI solutions to understand what the
      technology can do. Technical experimentation is healthy and important
      for agencies. If your agency is just trying to get exposure to
      Generative AI tools and their capabilities, it could be helpful to
      start with smaller problems and perhaps ones that are not mission
      critical, but ones that can’t be easily solved with current
      non-Generative AI tools.
    </p>

    <p>
      For ideas and inspiration of what problems and projects might be good
      to work on, see sections 1 and 2 of this guide. Agency use cases are
      also published on
      <a class="external_link" href="http://ai.gov">AI.gov</a> and may also
      be on your agency website.
    </p>
    <h2>3.3 Solutions Scoping and Testing</h2>

    <p>
      It’s often difficult to know which Generative AI tool will be best for
      your agency’s purposes. That’s why it’s always best to spend time
      actually trying them out first. The Integrated Product Team (IPT) can
      see which tools have the right combinations of functions and features
      that work with the data the agency has and help get to the goals the
      agency wants to achieve.
    </p>

    <h3>3.3.1 Categories of Generative AI Solutions</h3>
    <p>
      Knowing the agency’s priority problems to focus on and how Generative
      AI tools might address those needs, the IPT can scout potential
      Generative AI solutions. Perhaps they need tools that can analyze and
      generate initial text to jumpstart reporting. Perhaps they need
      Generative AI-enabled chatbots that can respond to public inquiries
      with specific information that an agency has uploaded in the LLM.
    </p>

    <p>
      The IPT can identify potential categories of solutions, which
      functions and features are needed to address the agency’s priority
      problems and initial performance requirements.
    </p>

    <p>
      For a starter list of Generative AI solutions categories, consider the
      typical Generative AI tools shown in section 1.5 of this guide.
    </p>

    <h3>3.3.2 Cloud Platform Sandboxes</h3>
    <p>
      No two Generative AI systems work exactly the same. What a supplier
      says their product can do might be close to what your agency wants or
      needs but may require tweaks to really make them work. At the same
      time, Generative AI systems are also evolving rapidly. Functions that
      don’t exist now might be available later.
      <a
        class="external_link"
        href="https://www.whitehouse.gov/wp-content/uploads/2024/03/M-24-10-Advancing-Governance-Innovation-and-Risk-Management-for-Agency-Use-of-Artificial-Intelligence.pdf"
        >OMB Management Memo M-24-10</a
      >
      provides a helpful reference about what sort of AI-enabling
      infrastructure and/or testing might best inform this process.
    </p>

    <p>
      Testing solutions before actually doing a full-scale purchase can help
      ensure the Generative AI products meet your specific agency’s needs.
      The IPT can then translate their experiences testing solutions into
      requirements and use cases for an acquisition plan and contract
      documents that will meet their goals.
    </p>

    <p>
      “Sandboxes” are test beds that agencies can use to experiment with
      Generative AI tools. Think of them as low scale versions of tech you
      are exploring. These sandboxes allow users to try different tools and
      identify which ones work best for your agency’s needs. They can also
      help more accurately estimate the amount of effort and cost it might
      take to complete the project.
    </p>

    <p>
      A subset of the IPT can bring their expertise in data, workflows and
      security to scope the sandbox and begin running tests with data and
      different Generative AI tools, subject to legal and policy
      restrictions and with appropriate safeguards.
    </p>

    <p>
      In many cases, the IPT can create a sandbox on a cloud platform that
      allows them to upload their data and try different Generative AI
      modules to see what kinds of results each gives. Because most
      Generative AI tools are available through cloud platforms this is an
      easy and relatively quick way to get started.
    </p>

    <p>
      Consider what data would be appropriate to use in a testing
      environment and what restrictions may apply to certain kinds of data
      (e.g., personally identifiable information, confidential business
      information, etc.). Until you have verified a system’s privacy and
      data security capabilities through an ATO process or FedRAMP
      certification, consider using only publicly available data in
      sandboxes.
    </p>

    <h4>Multiple Sandboxes</h4>
    <p>
      Some IPTs may even decide to set up multiple sandboxes on a few
      different cloud platforms so they can test both which modules work
      best for the agency’s needs and which platforms offer the most
      flexibility, lowest cost and best return on investment. Because each
      cloud platform and module works differently, be cautious and conduct
      individual security and privacy reviews for each sandbox before
      putting data into each sandbox.
    </p>

    <h4>Setting Up Sandboxes</h4>
    <p>
      Typically setting up and using these sandboxes can happen under the
      Simplified Acquisition Threshold (SAT) since they are used for small
      scale experiments. The IPT can create sandboxes using current
      contracts with a Value Added Reseller (VAR). The IPT may have to go
      through extra steps to access third party products through your
      sandbox. You may need to update or include new terms and conditions
      with the vendor. Consider creating a concept of operations (CONOPS) or
      charter with your agency’s CIO, CAIO and CISO organizations to operate
      these. Sandboxes that do not use government data and are not connected
      to the agency network allow for flexibility to experiment with new
      software quickly.
    </p>

    <h4>Performance Metrics and Evaluation</h4>
    <p>
      To get the most useful feedback about the Generative AI tool, test
      their performance in conditions that mirror how the tool will be
      deployed in the real world. The IPT can create metrics and evaluation
      criteria for testing and assessing the performance of solutions at any
      dollar threshold. If the tool will be used by the public or
      non-technical staff, the IPT may want to also conduct basic user
      experience, usability and accessibility testing of the tool across a
      range of devices (desktops, laptops, tablets and smartphones).
    </p>

    <h3>3.3.3 Non-Cloud Platform Sandboxes</h3>
    <p>
      Some tools may not be available through a traditional cloud platform.
      Working with the Generative AI tool vendor to use a trial version or
      create a custom sandbox for your agency might be needed. As with other
      testbeds, always make sure to check with your agency’s CIO, CISO, CAIO
      and OGC to ensure that the tools comply with all relevant security and
      privacy laws and policies.
    </p>

    <p>
      The IPT may opt to test “self-hosted” tools that sit on the agencies’
      own IT infrastructure and use “open source” models that are widely
      available rather than closed, proprietary systems. These options can
      offer greater control over the Generative AI tools and may save costs
      paid to external providers but may require more internal resources to
      manage.
    </p>

    <h3>3.3.4 Specifying Generative AI Solutions.</h3>
    <p>
      With some sense of what combinations of platform and Generative AI
      tools work for the data the agency has and the outcomes it wants, the
      IPT can determine what the agency will need to acquire.
    </p>

    <p>
      The agency may require access to a new cloud platform or to change the
      terms of use for an existing platform. The IPT may decide it needs to
      have access to several different Generative AI tools. The experiments
      they ran in the sandbox may show the need for several accounts and
      more “credits” to scale up operations. Engineers may decide that they
      want to be able to integrate Generative AI functions into their own
      systems and need access to APIs.
    </p>

    <p>
      Determine the products and services that the IPT needs to succeed, the
      quantities, the performance requirements and any other specifications
      needed to write a clear statement about what the agency is interested
      in purchasing. If the IPT needs a specific supplier’s products, start
      to assemble the information for a brand-name justification
    </p>

    <h3>3.3.5 Advanced Generative AI Options</h3>
    <p>
      Sandbox tests and other considerations may show that the IPT requires
      more sophisticated Generative AI capabilities. They may want to:
    </p>

    <ul>
      <li>
        <h4>Fine-tune a Pre-Trained Model</h4>
      </li>
    </ul>
    <p>
      LLMs rely on algorithms where different connections and information
      are given more or less “weight” or significance. Fine tuning is a
      process of changing those weights so different information is treated
      as more or less important.
    </p>

    <ul>
      <li>
        <h4>Customize a Pre-Trained Model</h4>
      </li>
    </ul>
    <p>
      LLMs are trained on a certain set of initial data. The LLM can be
      customized further with more up-to-date information or information
      relevant to a specific field which makes it significantly more useful
      or even links to searchable databases.
    </p>

    <ul>
      <li>
        <h4>Train and Fine-Tune a Model</h4>
      </li>
    </ul>
    <p>
      A team may decide that they want to take the basic architecture and
      algorithms of an LLM and train it on completely different data and
      weight the information in a very specific way. This can give a
      specialized result meant for a particular purpose.
    </p>

    <ul>
      <li>
        <h4>Build a Model</h4>
      </li>
    </ul>
    <p>
      A team may want to develop everything themselves from the ground up,
      crafting their own algorithms, determining their own weights of what
      information is more important and training it with its own data. This
      is a significant lift but may be necessary for very specific uses such
      as high-security applications.
    </p>

    <p>
      Typically these kinds of projects require greater effort, expertise,
      data security monitoring and oversight so IPTs should think deeply
      about the investment and whether the agency truly requires it.
    </p>

    <h2>3.4 Data Management and Protection</h2>

    <p>
      Data is at the heart of all Generative AI tools. The foundation models
      are trained on billions to trillions of pieces of data. Users can put
      new data in and the models will learn from that data. And Generative
      AI tools produce text, images and a whole host of other data. Properly
      protecting and managing that data as required by applicable law and
      policy is a critical consideration for any Generative AI acquisition.
    </p>

    <p>
      It’s critical to know what data was used to build and train the system
      initially and how the training data relates to the data you will use
      the Generative AI tool on, including potential implications for bias.
      It’s equally more important to know whether the data you input will be
      used to train and improve the system or whether it will be deleted
      after the query is complete. You’ll need to know how the data you
      input might be outputted to other users when responding to their
      prompts. And you will also want to understand how you can transfer to
      or use your data in other systems. The IPT can then identify, document
      and monitor where there are unknowns around the data outputs, usage
      and ownership.
    </p>

    <p>
      <a
        class="external_link"
        href="https://www.whitehouse.gov/wp-content/uploads/2024/03/M-24-10-Advancing-Governance-Innovation-and-Risk-Management-for-Agency-Use-of-Artificial-Intelligence.pdf"
        >OMB Management Memo M-24-10</a
      >
      has requirements for what data to review and issues to investigate.
    </p>

    <h3>3.4.1 Data Security</h3>
    <p>
      Using data responsibly and protecting data from unauthorized access
      are high priorities for data from both inside or outside of the
      government. Consult with your Agency’s Privacy Officer, CIO and
      Security Officer to assess data management requirements and risks. At
      the most basic level, data must be securely stored and securely
      transmitted. Secure networks prevent data from being compromised in
      transit.
    </p>

    <p>
      Protections prevent unauthorized access. If there is any chance
      information considered non-public by your agency officials would be
      used in a Generative AI tool, then those tools can only run on systems
      that have the right protections and safeguards in place. But even with
      publicly available information or information available for unlimited
      distribution, ensure that Federal data protection standards and
      regulations will be met. And because cyber threats are only getting
      worse, Generative AI systems must have proper cybersecurity systems
      including threat detection and risk mitigation.
    </p>

    <h3>3.4.2 Data Inventory</h3>
    <p>
      List the data that will be involved in the Generative AI tools the
      agency plans to use. Major types of data to manage include but isn’t
      limited to:
    </p>

    <ul>
      <li>
        Generative AI Training, Testing and Validation Data - This is the
        information that the manufacturer of the Generative AI tool used to
        create the LLM and see if it worked well.
      </li>

      <li>
        Generative AI Fine-Tuning Data - This is the information that either
        the manufacturer of the Generative AI tool or the users of the tool
        (including your agency) use to customize the LLM to better serve
        specific purposes.
      </li>

      <li>
        Agency Inputted Data - This is the information that the agency staff
        feeds into the model so the LLM can summarize it, find patterns and
        insights or transform it and the prompts that agencies put in to get
        answers from the LLM.
      </li>

      <li>
        Generative AI Outputted Data - This is the information that the LLM
        creates based on the training, testing and agency inputted data.
      </li>

      <li>
        Gen AI Code and Models - This is the set of algorithms and
        programming that make up the model itself.
      </li>
    </ul>

    <h3>3.4.3 Understanding How Data is Used</h3>
    <p>
      Understanding and identifying training and testing data, input data
      and output data are critical to managing a successful Generative AI
      project or program. Both users and owners of the tool and data have
      equities in how they are managed and used.
    </p>

    <p>
      Here are initial questions to help the IPT get a better sense of the
      data associated with the agency’s use of Generative AI, how to
      appropriately assess and mitigate risks, and how to ensure government
      data rights are protected. This list of questions is not exhaustive,
      nor will all the questions be applicable in every situation.
    </p>

    <h4>Generative AI Training, Testing and Validation Data</h4>
    <ul>
      <li>What data were used for training, testing and validation?</li>
      <li>What is the size of the data set?</li>
      <li>
        Is there a discernible geographic, age or other demographic with the
        data?
      </li>
      <li>
        What is the source of the data (e.g., agency data, social media,
        news, legal documents, scientific reports, etc.)?
      </li>
      <li>
        What was the context in which the data set was gathered or generated
        and what was its initial intended purpose(s)?
      </li>
      <li>Have any inherent biases been identified in the data?</li>
      <li>What biases are likely present in the data?</li>
      <li>
        Are there allegations of copyright infringement or pending court
        cases which might impact the data set and tool?
      </li>
    </ul>
    <ul>
      <li>
        Have there been any studies on the data that may indicate prior use
        and intent?
      </li>
    </ul>

    <h4>Agency Inputted Data</h4>
    <ul>
      <li>Who generated the data?</li>
      <li>
        What was the context in which the data set was gathered or generated
        and what was its initial intended purpose(s)?
      </li>
      <li>
        Are agency inputs stored by vendors? If so, what are the limitations
        on how vendors use that data?
      </li>
      <li>
        How will the data you input be used to train the system and make it
        better?
      </li>
      <li>
        How might the data you input be shared with other users when
        responding to their prompts?
      </li>
    </ul>

    <h4>Generative AI Outputted Data</h4>
    <ul>
      <li>Who owns the IP generated by AI tools (e.g. software code)?</li>
      <li>Who owns the model once the contract ends?</li>
      <li>
        Will outputted data be used to train the Generative AI model you are
        using or another model with or without your knowledge?
      </li>
      <li>
        Could outputted data impact citizen entitlements, benefits or
        rights?
      </li>
      <li>
        Does the agency have the ability to assess, monitor and control
        outputs?
      </li>
      <li>What kinds of outputs does the system filter out?</li>
      <li>Who owns the outputs from the tool?</li>
      <li>
        Does the agency have the ability to assess, monitor, and control
        outputs?
      </li>
      <li>Can the outputs be explained?</li>
    </ul>

    <h4>Generative AI Model</h4>
    <ul>
      <li>
        Will you be able to input your own data to get better results?
      </li>
      <li>
        How have other users’ data been incorporated back into the model?
      </li>
      <li>
        When was the last time the model was updated and what was changed?
      </li>
      <li>
        Was specific data used to “fine tune” the model? If so, what were
        the characteristics of those data?
      </li>
      <li>
        What steps have you taken to ensure the data used for “fine tuning”
        are suitable for the intended use case?
      </li>
      <li>
        Will agency data be used to train the Generative AI model you are
        using?
      </li>
      <li>Who owns the model once the contract ends?</li>
      <li>
        Does the model have any sort of history of bias or ethical
        challenges that have not been corrected?
      </li>
      <li>Are there any risks of data leakage?</li>
      <li>
        Could use of the model inadvertently synthesize information in a way
        that makes the output more sensitive than the input?
      </li>
      <li>
        Could use of the model inadvertently synthesize sensitive or CUI
        information or information perceived to be sensitive or CUI?
      </li>
      <li>
        What kinds of protections or submodels are being formed with data
        that could inadvertently lead to adverse outcomes for government
        customers
      </li>
    </ul>

    <p>
      Generative AI’s need for training data raises questions and privacy
      concerns about where, when and how that data was collected. Model
      cards and similar resources can help explain the origin and nature of
      the training data and quantify the risk of bias, discrimination or
      similar harm to people.
    </p>

    <p>
      Generative AI applications are built on training data. Understanding
      the data, its biases and its current applications and usage will help
      to identify whether a particular application or model is more
      appropriate to meet needs.
    </p>

    <p>
      The CAIO of the agency is responsible for ensuring that Generative AI
      systems comply with relevant standards as detailed in
      <a
        class="external_link"
        href="https://www.whitehouse.gov/wp-content/uploads/2024/03/M-24-10-Advancing-Governance-Innovation-and-Risk-Management-for-Agency-Use-of-Artificial-Intelligence.pdf"
        >OMB Management Memo M-24-10</a
      >. Acquisition staff can assist by documenting their process and
      decisions.
    </p>

    <p>
      Asking suppliers to share information about their products helps
      acquisition staff know that there is transparency and accountability
      in the procurement. At the same time, it helps the IPT and CAIO
      jointly monitor compliance later.
    </p>

    <p>
      One example of a “declaration form” for a Generative AI tool was
      created by the GovAI Coalition, a group of public servants from over
      150 local, county, and state governments. See their
      <a
        class="external_link"
        href="https://www.sanjoseca.gov/home/showpublisheddocument/109730/638458752830000000"
        >AI Fact Sheet for Third Party Systems</a
      >.
    </p>

    <h3>3.4.4 Potential Data-Related Risks</h3>
    <p>
      This guide lists some but not all of the potential risks of Generative
      AI in Section 1 including Misinformation and Disinformation, Privacy,
      Bias and Discrimination and Security/Cybersecurity. Clarifying ethical
      challenges related to data and completing a risk assessment are
      potential ways to identify risks for data and determine how to monitor
      and mitigate them.
    </p>

    <h4>Clarify ethical challenges.</h4>
    <p>
      Documents like the
      <a
        class="external_link"
        href="https://www.whitehouse.gov/ostp/ai-bill-of-rights/"
        >Blueprint for an AI Bill of Rights</a
      >
      and the
      <a class="external_link" href="https://rai.tradewindai.com/"
        >Tradewinds Responsible AI Toolkit</a
      >
      are published ethical frameworks that help explain what issues to
      prioritize.
    </p>

    <p>From the Responsible AI website:</p>

    <p>
      “The Responsible Artificial Intelligence (RAI) Toolkit provides a
      centralized process that identifies, tracks, and improves alignment of
      AI projects to RAI best practices and the DoD AI Ethical Principles,
      while capitalizing on opportunities for innovation. The RAI Toolkit
      provides an intuitive flow guiding the user through tailorable and
      modular assessments, tools, and artifacts throughout the AI product
      lifecycle. The process enables traceability and assurance of
      responsible AI practice, development, and use.”
    </p>

    <h4>Complete a risk assessment.</h4>
    <p>
      For each of the areas listed above, the IPT can capture both what
      might go wrong and the potential harm, damage or loss that the agency
      would suffer if that happened.
    </p>

    <p>
      The Responsible AI Toolkit also has a guide on risk. “The
      <a
        class="external_link"
        href="https://rai.tradewindai.com/appendix/dagr"
        >Responsible Artificial Intelligence (RAI) Defense AI Guide on Risk
        (DAGR)</a
      >
      is intended to provide DoD AI stakeholders with a voluntary guide to
      promote holistic risk captures and improved trustworthiness,
      effectiveness, responsibility, risk mitigation, and operations.” It is
      also a valuable resource for non-DoD agencies.
    </p>

    <p>
      The
      <a
        class="external_link"
        href="https://nvlpubs.nist.gov/nistpubs/ai/NIST.AI.100-1.pdf"
        >NIST Risk Management Framework (RMF)</a
      >
      helps to better manage risks to individuals, organizations, and
      society associated with artificial intelligence (AI) by incorporating
      trustworthiness considerations into the design, development, use, and
      evaluation of AI products, services, and systems. The accompanying
      <a
        class="external_link"
        href="https://airc.nist.gov/AI_RMF_Knowledge_Base/Playbook"
        >NIST AI RMF Playbook</a
      >
      provides suggested actions for achieving the outcomes laid out in the
      AI Risk Management Framework (AI RMF). Suggestions are aligned to each
      sub-category within the four AI RMF functions (Govern, Map, Measure,
      Manage). The Playbook is neither a checklist nor set of steps to be
      followed in its entirety. Playbook suggestions are voluntary.
      Organizations may utilize this information by borrowing as many – or
      as few – suggestions as apply to their industry use case or interests.
    </p>

    <h2>3.5 Acquisition Strategy</h2>

    <p>
      <a
        class="external_link"
        href="https://www.acquisition.gov/far/34.004#:~:text=34.004%20Acquisition%20strategy.%20The%20program%20manager%2C%20as%20specified,in%20the%20most%20effective%2C%20economical%2C%20and%20timely%20manner."
        >FAR 34.004</a
      >
      defines the acquisition strategy as “the program manager’s overall
      plan for satisfying the mission needs in the most effective,
      economical, and timely manner” and
      <a
        class="external_link"
        href="https://www.acquisition.gov/far/subpart-7.1"
        >FAR 7.1 </a
      >identifies the components of an acquisition plan.
    </p>

    <p>
      With the IPT having defined the agency’s goals, tested Generative AI
      solutions in sandboxes, developed requirements and defined how data
      will be managed, you can map out what you intend to buy and how you
      intend to buy it. You can specify the performance metrics of the
      Generative AI products, tools, functions, modules or add-ons that will
      best serve the agency based on the sandbox tests the IPT completed.
      There are multiple ways to answer the question of “how to buy it.”
    </p>

    <h3>3.5.1 The fastest acquisition may be no new acquisition.</h3>
    <p>
      Generative AI tools are often software delivered via the web or
      “Software as a Service” (SaaS). So like other SaaS tools most
      Generative AI tools are easily available through cloud platforms,
      other software packages and publicly-available websites.
    </p>

    <p>
      Generative AI tools may already be available to agency staff. They
      might have them in tools they already use every day. Generative AI
      tools may be accessible through existing government cloud platforms.
      And they may be available through professional service and system
      integrator contracts agencies already have in place.
    </p>

    <p>
      That means your agency might be able to access Generative AI solutions
      without doing a new acquisition.
    </p>

    <p>
      In that way, the fastest acquisition for Generative AI tools may be no
      new acquisition, or as simple as adding “credits” to an existing cloud
      platform contract to account for the new requirements or resources
      associated with the Generative AI tools.
    </p>

    <p>
      Of course the fastest or easiest solutions may not be the best for the
      agency in the short and/or long term. Work with the IPT to manage
      issues of competition and vendor lock in.
    </p>

    <p>
      Before embarking on a large scale or involved process for scoping and
      conducting a new acquisition for Generative AI tools, see if there is
      a simpler route. Work with your agency’s Chief Information Officer,
      Chief Artificial Intelligence Officer and Chief Information Security
      Officer to determine what you already have in place and whether you
      can just use an existing solution or contract.
    </p>

    <p>Here are a few options:</p>

    <h4>From public web tools you can access</h4>
    <p>
      Many providers offer basic Generative AI tools and services from a
      freely available public page or a search page. If your agency staff’s
      Generative AI needs are basic, consider using one of these basic, free
      tools. This might only be acceptable in very few use cases. Also note
      that use of free public tools will likely limit the data you can use
      and the amount of information available to address some of the risks
      and concerns identified in previous sections, so carefully consider
      these limitations before use. Review the terms of service with your
      agency’s legal team before using these tools to ensure compliance.
    </p>

    <h4>In software you have</h4>
    <p>
      Lots of software packages have basic Generative AI functionality built
      in. Before you start a new acquisition, check with your agency’s IT
      group. You may already have access to the right Generative AI tools
      within your existing software.
    </p>

    <h4>Via a cloud platform you use</h4>
    <p>
      Many cloud platforms and “hyperscalers” provide access to Generative
      AI tools as modules from right within their platforms. Agency staff
      might be able to use their current cloud platform accounts and credits
      to pay for and use those modules if it is within the scope of the
      underlying, pre-existing contract.
    </p>
    <h5>
      Best Practices when Accessing Generative AI Tools via a Cloud Platform
    </h5>
    <ul>
      <li>
        Get formal risk management approval from the OCIO, CISO, CAIO and
        OGC. The EO stipulates AI use cases need to be risk managed by
        contract authorities or agency IT. If there is not yet a formalized
        process, document your approvals from the relevant agency officials.
      </li>
      <li>
        Consider creating a concept of operations (CONOPS) or charter with
        your agency’s CIO, CAIO and CISO organizations to operate these.
      </li>
      <li>
        Identify which cloud platforms your agency has access to, which
        office(s) own the contracts and what the terms and conditions are.
        In many cases, the contract and contracting officer are assigned to
        the CIO organization.
      </li>
      <li>
        Prioritize security even for experiments. Choose cloud platforms and
        modules that have received FedRAMP authorizations. Understand how
        your data may be used to train the model or improve outputs, with
        and without your consent.
      </li>
      <li>
        Develop a cost estimate based on the pricing in the contract. If the
        contract is with a Value Added Reseller, there may be management
        costs for the vendor in addition to the credits needed to stand up
        the environment.
      </li>
      <li>
        Ensure you are getting access to the right version of the platforms.
        Many cloud platforms have different versions for commercial and
        government each with special security options and pricing models.
        You may also need to request permission to access Generative AI
        modules if there are only test versions available for federal
        environments.
      </li>
    </ul>

    <h4>
      From a professional services provider or IT system integrator on
      contract
    </h4>
    <p>
      A growing number of consultants are offering Generative AI access
      through their existing professional services contracts. IT system
      integrators have also built Generative AI tools and interfaces to
      others’ tools. Agency staff can sometimes access such tools through a
      custom portal or from software that the consultant or SIs have
      deployed. Depending on their contract and task order, a consultant or
      SI might already be able to provide or build a custom solution to
      provide access to Generative AI tools.
    </p>

    <p>
      With any of the above options, keep in mind that even though you might
      not do a new acquisition you may still need to modify the terms and
      conditions of an existing contract, obligate funds to buy more credits
      or upgrade subscriptions or exercise an option.
    </p>

    <p>
      And of course, especially for what looks to be “free,” check with your
      agency’s Chief Information Officer, Chief Artificial Intelligence
      Officer and Chief Information Security Officer to ensure the tools
      meet all appropriate regulations, standards and policies.
    </p>

    <h3>3.5.2 Acquisition Channels for Generative AI</h3>
    <p>
      If you need to do an acquisition to access Generative AI tools a few
      options exist. The acquisition method or vehicle you choose may
      influence which of these options is most appropriate. As with any
      acquisition, existing providers should be a consideration and not a
      requirement that impedes competition
    </p>

    <h4>
      Acquire access to Generative AI tools or functions within software you
      already have.
    </h4>
    <p>
      Typically the acquisition process for getting these Generative AI
      features will look like paying more for a higher subscription or to
      move up to the next feature tier that has the more expensive
      functions. If you procure that software through a Value Added Reseller
      (VAR) there may be a management fee in addition to the cost of
      Generative AI tools access.
    </p>

    <p>
      Note that many software providers are adding Generative AI
      capabilities into existing software. Ensuring you review any changes
      to the functionality or the terms and conditions will help you to
      identify whether these capabilities are present in new software
      updates and deliveries.
    </p>

    <h4>
      Acquire access to Generative AI tools directly from the manufacturer.
    </h4>
    <p>
      The acquisition process will probably look like paying the
      manufacturer according to their pricing structures. The manufacturer
      may use a Value Added Reseller (VAR) who may charge a management fee
      in addition to the cost of Generative AI tools access.
    </p>
    <h4>
      Acquire access to a cloud platform and Generative AI tools through
      that platform.
    </h4>
    <p>
      The acquisition process should involve procuring access to the cloud
      platform and then paying for using the Generative AI tools. Many of
      the cloud platforms use resellers who may charge a management fee in
      addition to the cost of Generative AI tools access.
    </p>
    <h4>
      Acquire access to Generative AI tools through a system integrator.
    </h4>
    <p>
      System integrators all have different pricing models but you can
      expect to find many that bill as professional services by the hour,
      week or month. They may charge separately for Generative AI tools
      access.
    </p>
    <p>
      Many Generative AI tool manufacturers use multiple channels for their
      products. They sell their tools directly, they use resellers and they
      make their tools available through cloud platforms and system
      integrators. Often the prices vary among the channels – in some cases
      you have to pay if you go to the manufacturer but you can get limited
      uses of products for free through partners.
    </p>

    <p>
      Look carefully at the different acquisition options and determine what
      best meets your agency’s needs. Identify which options offer…
    </p>

    <ul>
      <li>The trackable, transparent and cost-effective pricing models</li>
      <li>
        The flexibility and scalability for changing users, usage or use
        cases
      </li>
      <li>
        The terms and conditions for proper security and data management
      </li>
      <li>The ease for agency staff to access and use the tool</li>
      <li>
        The speed of acquiring access once the solicitation is released
      </li>
    </ul>

    <h4>Custom Solutions</h4>
    <p>
      In certain cases, the IPT may decide it needs more than just access to
      Generative AI tools and actually needs a custom solution that is
      tailored or built specifically for their use. Such acquisitions may
      end up looking like other purpose-built software purchases in pricing,
      terms and conditions and process.
    </p>

    <h3>3.5.3 Acquisition Vehicle Selection</h3>
    <p>
      You can choose from many options of acquisition vehicles, including
      governmentwide acquisition contracts. This guide includes a list of
      potential acquisition vehicles available for civilian agencies. Some
      vehicles will be a better fit for your agency’s particular needs. A
      few questions to ask as you evaluate which acquisition vehicle might
      be best to use for your needs:
    </p>

    <ul>
      <li>Does your agency have an anticipated contract type?</li>
    </ul>
    <p>
      Your agency may prefer or need to use a certain type of contract.
      There are multiple contract types outlined in
      <a
        class="external_link"
        href="https://www.acquisition.gov/far/part-16"
        >FAR Part 16</a
      >
      such as fixed price, cost reimbursement and time and materials. Not
      every acquisition vehicle can accommodate all contract types. It is
      important to research whether the anticipated contract type aligns
      with a specific vehicle.
    </p>

    <ul>
      <li>Is the acquisition vehicle designated Best-in-Class?</li>
    </ul>
    <p>
      Your agency may benefit from using acquisition vehicles that have been
      designated Best-in-Class (BIC) by the Office of Management and Budget
      (OMB). BIC vehicles maximize the government’s shared purchasing power,
      allowing agencies to leverage volume discounts; help agencies operate
      more efficiently by reducing administrative costs and contract
      duplication; and expand sharing of government-wide buying data,
      leading to better-informed decisions.
    </p>

    <ul>
      <li>
        Does your agency have specific socio-economic requirements or
        targets?
        <br />
        Your agency may plan to set-aside a contract requirement to target
        certain socioeconomic categories such as Veteran-Owned Small
        Businesses (VOSBs) or those in the 8(a) Business Development
        program. Some vehicles provide easy ways to access such suppliers.
      </li>
    </ul>

    <ul>
      <li>
        Does your agency have budget/resource constraints?
        <br />
        Your agency may need to keep to a strict dollar limit for a
        purchase. Some vehicles have negotiated better prices or fees in
        exchange for the buying agency taking on more of the burden of the
        acquisition from reporting to compliance checks.
      </li>
    </ul>

    <ul>
      <li>Does your agency have preferred or approved vehicles?</li>
    </ul>
    <p>
      Your agency may have identified particular contracts as part of its
      strategic sourcing efforts that it prefers to use. Some vehicles may
      be designated as preferred or even mandatory vehicles because they
      meet your agency priorities and not using these vehicles would require
      a waiver.
      <br />
    </p>
    <ul>
      <li>
        Does your agency have its own capacity to verify compliance?
        <br />
        Your agency may prefer to not worry about reviewing or verifying
        whether suppliers are in compliance with relevant policies and
        regulations. Some vehicles have pre-negotiated terms and conditions
        that ensure suppliers comply with such rules.
      </li>
    </ul>

    <ul>
      <li>
        Are the products or services you need available on the vehicle you
        plan to select?
      </li>
    </ul>
    <p>
      Your agency may have very specific requirements for the solutions they
      are trying to procure. Some vehicles may have the right suppliers or
      products available while others do not.
    </p>

    <p>
      See Section 4 for a list of relevant acquisition methods and vehicles.
    </p>

    <h2>3.6 Market Assessment</h2>

    <h3>3.6.1 Market Research</h3>
    <p>
      The marketplace for Generative AI technologies and vendors is changing
      every day. Large Generative AI companies, universities, small
      businesses and new upstarts are all announcing new tools, capabilities
      and features constantly. Generative AI is such a popular topic that
      there are multiple articles on these advancements every day. You can
      stay informed about the latest AI technologies and vendors by
      monitoring tech and Federal IT news websites.
    </p>

    <p>
      It can still be difficult to know which resellers, vendors and
      manufacturers to look at for a particular acquisition. Those on
      government contracts are a good starting place. Here are a few other
      resources:
    </p>

    <ul>
      <li>
        Search tools on acquisition program websites like
        <a
          class="external_link"
          href="https://gsaelibrary.gsa.gov/ElibMain/home.do"
          >GSA’s eLibrary</a
        >
        and
        <a class="external_link" href="https://cic.gsa.gov/"
          >Cloud Information Center</a
        >
        provide easy ways to find suppliers.
      </li>
    </ul>

    <ul>
      <li>
        The Federal Acquisition Service (FAS) also runs a free
        <a
          class="external_link"
          href="https://www.gsa.gov/about-us/organization/federal-acquisition-service/customer-and-stakeholder-engagement/market-research-as-a-service-mras"
          >Market Research as a Service (MRAS)</a
        >
        offering for agencies to craft targeted asks of industry that can
        then inform those agencies’ Generative AI acquisitions.
      </li>
    </ul>

    <ul>
      <li>
        The
        <a
          class="external_link"
          href="https://itvmo.gsa.gov/services/market-and-it-data-intelligence/"
          >Governmentwide IT Vendor Management Office (ITVMO)</a
        >
        is the government’s trusted advisor and advocate for smarter, faster
        IT buying.
      </li>
    </ul>

    <ul>
      <li>
        The
        <a
          class="external_link"
          href="https://www.tradewindai.com/solutions-marketplace"
          >Tradewinds Solutions Marketplace</a
        >
        offers ways to broadcast and manage AI opportunities to industry,
        interface with an ecosystem of partners and companies that can
        delivery AI technologies and peruse a digital repository of pitch
        videos, which address challenges in the AI/ML, digital, and data
        analytics space.
      </li>
    </ul>

    <ul>
      <li>
        This guide contains a data dashboard for recent obligations around
        Generative AI.
      </li>
    </ul>

    <h3>3.6.2. FedRAMP Authorization</h3>
    <p>
      As many Generative AI products are cloud based offerings complying
      with Federal security rules around cloud services is essential.
    </p>

    <p>
      Products which have gone through the FedRAMP process have undergone a
      significant review of security documentation, testing and validation
      which can accelerate CIO approval for a product to be incorporated
      into an agency network. The
      <a
        class="external_link"
        href="https://marketplace.fedramp.gov/products"
        >FedRAMP Marketplace</a
      >
      is a searchable and sortable database of cloud service offerings that
      have achieved a FedRAMP designation
    </p>

    <p>
      FedRAMP also published a draft
      <a
        class="external_link"
        href="https://www.fedramp.gov/assets/resources/documents/FedRAMP_DRAFT_Emerging_Technology_Prioritization_Framework.pdf"
        >Emerging Technology Prioritization Framework</a
      >. This document describes the operational framework for how FedRAMP
      will prioritize certain cloud service offerings that utilize specific
      emerging technologies.
    </p>

    <p>
      The prioritization process will be integrated into existing and future
      FedRAMP authorization paths. The prioritization framework will not
      create additional authorization pathways and will maintain the same
      rigorous and thorough authorization requirements.
    </p>

    <h3>3.6.3 Vendor Diligence</h3>
    <p>
      Acquisition professionals are used to conducting due diligence on
      suppliers. Generative AI is an emerging field with new players arising
      all the time. Knowing which vendors can deliver on their promised
      results is difficult and a big reason to test solutions before
      acquiring them using techniques like sandboxes discussed in Section
      3.3.
    </p>
    <p>
      Standard due diligence on companies is still important. Looking at
      their track record as a government supplier, their financial health
      and their past performance are all good indications (but not
      guarantees) of how they might perform on an acquisition you run.
    </p>
    <p>
      At the same time, because this field is emerging, some companies doing
      sophisticated and powerful work have been in business for less than 10
      years. Aside from the older, larger and established IT players, many
      of the Generative AI companies aren’t registered government suppliers
      yet.
    </p>

    <p>
      Because many Generative AI solutions may be accessed through a cloud
      provider, a partner, a systems integrator or a reseller, you may need
      to do some extra work to understand both the vendor’s and
      manufacturer’s ability to deliver. Ask about what access the team may
      have to the Generative AI tool manufacturer even through the contract
      may be with another entity.
    </p>

    <p>
      Reviewing the commercial terms and conditions for software and data
      use helps ensure data use and the products themselves meet the
      government requirements for security and data ownership.
    </p>

    <p>
      The
      <a class="external_link" href="https://itvmo.gsa.gov/about/"
        >Governmentwide ITVMO</a
      >
      increases agency knowledge on commonly used and emerging vendors,
      especially small businesses, that offer IT services and products in
      the Federal IT Marketplace.
    </p>

    <h2>3.7 Cost Estimation</h2>

    <p>
      Given the large amount of IT budget that often has to go towards
      ongoing operation and maintenance, costs can be a significant
      impediment to Generative AI acquisition.
    </p>

    <p>
      Generative AI systems are software systems. Suppliers bill for them
      mostly like other “Software as a Service” (SaaS) tools with some
      slight variants. You may need to pay for both monthly access to the
      Generative AI system plus how much time you use it plus how much data
      you input or output.
    </p>

    <h4>
      Costs for using Generative AI tools can add up quickly and
      unpredictably.
    </h4>
    <p>
      Setting up systems to accurately forecast and check actual costs
      against the budget when using Generative AI tools helps address
      concerns about growing consumption costs.
    </p>

    <p>
      Understand your agency’s users, use cases, desired outcomes and
      internal policies to help develop accurate estimates.
    </p>

    <p>
      Having an understanding of fiscal law principles associated with
      purchasing SaaS and Cloud will help you to appropriately structure and
      manage your Generative AI project.
    </p>

    <h3>3.7.1 Generative AI tools are sold like software.</h3>
    <p>
      Again, most commercial Generative AI tools are considered “software”
      so they tend to be sold the way most software is sold and priced
      nowadays. Agencies pay fees for software in three main ways:
      subscriptions, usage and feature tiers.
    </p>

    <ul>
      <li>
        <h4>Subscriptions</h4>
      </li>
    </ul>
    <p>
      Agency pays per month or year for each account that renews at the end
      of the term until canceled, regardless of how much you use the model.
      Think of this like the fee you might pay for a video streaming
      service: you can watch as much as you want for a flat fee per month or
      per year.
    </p>

    <ul>
      <li>
        <h4>Usage</h4>
      </li>
    </ul>
    <p>
      Agency identifies and obligates funding for requirements, which is in
      turn billed for the amount of data inputted or outputted, the time or
      resources used on a particular platform or the quality of output.
      Think of this like the fee you might pay for a rideshare: you pay for
      the length of the trip, the time the trip takes and a little more if a
      lot of people are trying to get rides at the same time.
    </p>

    <ul>
      <li>
        <h4>Feature Tiers</h4>
      </li>
    </ul>
    <p>
      Agency pays once per the group of functions and features regardless of
      consumption/usage or number of users. Think of this like the one-time
      fee you might pay for a membership: you pay one fee to the club which
      entitles you to lifetime benefits and if you pay a higher fee you get
      more benefits like access to exclusive sales.
    </p>

    <p>
      Generative AI tools typically charge some combination of these fees.
      Here are a few examples based on real life cases:
    </p>

    <ul>
      <li>
        A reseller charges an agency $20 per month per user for email, word
        processing, spreadsheets and presentations programs and apps. They
        charge an additional $20 per month for Generative AI features and
        functions in these same programs and apps.
      </li>
    </ul>

    <ul>
      <li>
        A company offers the ability to “train” an AI model charges an
        agency a base rate per month for an account plus a $10 per million
        credits or tokens where each token represents an individual word of
        “training data” that the agency uploads.
      </li>
    </ul>

    <ul>
      <li>
        A cloud platform provider charges a certain amount to get access to
        a Generative AI model but then charges the agency for every minute
        they use the model or for every time they access a database that the
        model connects to.
      </li>
    </ul>

    <h3>3.7.2 Estimating the Costs of Generative AI Solutions</h3>
    <p>
      To estimate the costs of Generative AI solutions, start by
      understanding the fees that the supplier would charge then ask
      questions to quantify accounts, users, time and usage.
    </p>
    <table class="usa-table">
      <caption>
        Fees paid by agency
      </caption>
      <thead>
        <tr>
          <th scope="col">Subscriptions</th>
          <th scope="col">Usage</th>
          <th scope="col">Feature Tiers</th>
        </tr>
      </thead>
      <tbody style="vertical-align: top">
        <tr>
          <td data-label="Subscriptions">
            Per month or year for each account that renews at the end of the
            term until canceled.
          </td>
          <td data-label="Usage">
            Per the amount of data inputted or outputted, the time or
            resources used on a particular platform or the quality of
            output.
          </td>
          <td data-label="Feature Tiers">
            Per the group of functions and features regardless of
            consumption/usage or number of users.
          </td>
        </tr>
      </tbody>
    </table>

    <table class="usa-table">
      <caption>
        Questions to ask when estimating costs
      </caption>
      <thead>
        <tr>
          <th scope="col">Subscriptions</th>
          <th scope="col">Usage</th>
          <th scope="col">Feature Tiers</th>
        </tr>
      </thead>
      <tbody style="vertical-align: top">
        <tr>
          <td data-label="Subscriptions">
            <p>How many unique accounts does the agency program need?</p>
            <p>
              How long will we need accounts for (a few months, a year or
              more)?
            </p>
            <p>
              What other base subscriptions are required to access the
              service?
            </p>
            <p>
              Do we need a service or support layer to help us use the
              tools?
            </p>
          </td>
          <td data-label="Usage">
            <p>How much data will we input?</p>
            <p>How much data will we output?</p>
            <p>What quality of output do we want?</p>
            <p>
              How much time (per day and per month) will the AI service be
              used?
            </p>
            <p>How many different tools will use the AI service?</p>
            <p>
              Do we need a service or support layer to help us use the
              tools?
            </p>
          </td>
          <td data-label="Feature Tiers">
            <p>
              What features do we need to use and which tiers support those
              features?
            </p>
            <p>
              What are the limits (number of accounts, total usage, etc.)
              for using those AI tools at that tier of service?
            </p>
            <p>
              Can we customize the features we buy in each tier or are they
              preset?
            </p>
            <p>
              Do we need a service or support layer to help us use the
              tools?
            </p>
          </td>
        </tr>
      </tbody>
    </table>

    <h3>3.7.3 Developing estimates for using Generative AI tools</h3>
    <p>
      Subscription pricing generally is straightforward: estimate the number
      of users and the costs. As Generative AI tools are new and companies
      are still figuring out their own costs and revenues these rates may
      change, these costs may change. Though you should always try to
      negotiate for discounts from listed prices, companies are rarely
      offering reduced prices for tools at this time so listed prices are
      realistic for estimating purposes.
    </p>

    <p>
      When accessing generative AI tools through a usage based model,
      account for any type of access costs in addition to actual usage. For
      example, if you are accessing a generative AI tool through your Cloud
      provider’s architecture and you use a Value Added Reseller (VAR) for
      that architecture, your estimate will need to include any costs the
      VAR charges in addition to your usage costs. It is also important to
      understand and account for any additional access charges your Cloud
      provider may add on top of their usage costs and the usage costs for
      the particular generative AI tool.
    </p>

    <p>
      Similar to subscription pricing, estimating costs for software feature
      tiers is generally straightforward but offerings within tiers and
      pricing may change more frequently as companies develop and integrate
      generative AI models and capabilities into their products.
    </p>

    <p>
      Four of the largest Cloud Service Providers (CSPs) provide cost
      calculators to assist in estimating a budget and developing a cost
      estimate. Other CSPs may provide similar tools and serve as a basis
      for your estimate. Successfully using these tools requires the
      estimator to have knowledge of the potential workload and types,
      processing speeds and memory needed as well as the number of users.
      Consult with technical experts in your organization and use more than
      one of the tools when building your estimate and ensure you coordinate
      with your legal team on how to appropriately obligate funding.
    </p>

    <p>
      Setting up an agency “test bed” or “sandbox” for a particular
      Generative AI model and constructing an experiment is one way to
      understand and start to estimate potential usage costs.
    </p>

    <p>
      When constructing technical architectures the IPT will have visibility
      and options on which components it chooses to use and the associated
      costs with each particular component. Ensuring CORs and end users
      communicate often during the development process and operations of the
      tools will help manage your spend.
    </p>

    <p>
      An overview on pricing for general Cloud services can be found in the
      <a
        class="external_link"
        href="https://cic.gsa.gov/acquisitions/pricing"
        >pricing resource page of the Cloud Information Center</a
      >.
    </p>

    <p>
      Agencies may find they need to contract for specific services to
      develop, tune and maintain their models. Contracting officers should
      reach out to their CAIO’s office to identify the most relevant labor
      categories or skill sets for the particular requirements if this is
      needed. Use tools such as GSA’s
      <a class="external_link" href="https://buy.gsa.gov/pricing/">CALC</a>
      to help develop estimates if you have an understanding of appropriate
      labor categories and skill levels.
    </p>

    <h2>3.8 Performance Monitoring and Evaluation</h2>

    <p>
      Generative AI tools are constantly learning and changing. Once a tool
      is implemented, the IPT must closely monitor how it is used and the
      outputs. Consider provisions in contracts requiring vendors to submit
      deliverables that help monitor and control for risks in using the
      tools.
    </p>

    <h3>3.8.1 Maintaining the IPT</h3>
    <p>
      Continuing the Generative AI IPT for the full lifecycle of using the
      tool brings multiple benefits.
    </p>

    <h4>Training</h4>
    <p>
      The IPT can develop or collect and make available appropriate training
      materials and deliver them to the end users. Part of this training
      should identify the changing nature of generative AI tools to help
      identify if the product is not functioning correctly.
    </p>

    <h4>Incident Detection and Response</h4>
    <p>
      Build in reporting and redress procedures for when something goes
      wrong working in collaboration with your agency’s teams that address
      IT risks. This is particularly important when Generative AI tools and
      their outputs may be used in a manner impacting benefits, rights or
      norms. Robust bias detection and mitigation strategies help to stay
      ahead of problems. Audit and oversight mechanisms can flag when
      incidents occur and when model performance is degrading. All of these
      will help identify when models may need to be refreshed, modified, or
      taken out of production.
    </p>

    <h4>Strategic Objectives</h4>
    <p>
      Regularly reviewing and adjusting Generative AI strategies helps
      ensure they remain effective and aligned with your agency’s goals.
    </p>

    <h3>3.8.2 Engage regularly with vendors</h3>
    <p>
      The inputs and outputs of Generative AI tools may change the
      functionality and performance of the product. Successfully managing a
      Generative AI acquisition requires frequent communication with
      vendors.
    </p>

    <h4>Meeting Performance and Ethical Standards</h4>
    <p>
      Before contract award (even at the solicitation stage and/or built
      into evaluation criteria), meeting with vendors can offer the chance
      to clearly define how they will meet performance and ethical standards
      and mitigate risks associated with the tool. Clarify the roles and
      responsibilities of vendors, particularly if a use case has an impact
      on citizen rights, entitlements or other benefit programs.
    </p>

    <h4>Resolving Disputes</h4>
    <p>
      Agree on areas of uncertainty that exist with the generative AI tool
      and how to navigate issues or disputes between the government and the
      vendor providing the model. Document these agreements and identify a
      cadence to review and update them ensuring your legal support is
      included in the process.
    </p>

    <h4>Updating Products</h4>
    <p>
      Identify procedures to measure and support trust and assurance for
      products. This should include testing and system update cycles and
      identifying new capabilities incorporated into the products. Also
      regularly review any changes in commercial terms and conditions around
      data and data usage. Consider doing this through a Service Level
      Agreement (SLA) or other mechanism which the IPT can use to monitor
      vendor performance.
    </p>

    <h4>Protecting Legal Rights</h4>
    <p>
      Where systems may support decisions on rights-impacting programs make
      sure the models can be contested in accordance with the laws, statutes
      and regulations governing the program.
    </p>

    <h4>Controlling Expenses and Costs</h4>
    <p>
      Monitor costs against the cost estimates you created during the
      acquisition. Make sure invoices contain sufficient detail to monitor
      and control expenditures, particularly usage or consumption costs.
      Regularly communicate with end users and the technical team, and
      review invoices to make sure they are in alignment with how the
      Generative AI tools are being used.
    </p>
  </div>
</div>
